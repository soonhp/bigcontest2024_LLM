from graphrag.get_embedding_model import get_embedding_model
from llm_response.langgraph_graph_state import GraphState
import streamlit as st
import re

from prompt.text_to_cypher_for_recomm import EXAMPLES_COMBINED, NEO4J_SCHEMA_RECOMM, TEXT_TO_CYPHER_FOR_RECOMM_TEMPLATE
from utils import get_candidate_str
import time


# ë§ˆí¬ë‹¤ìš´ì—ì„œ HTMLë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def convert_markdown_to_html(text):
    # **bold** -> <b>bold</b>
    text = re.sub(r'\*\*(.*?)\*\*', r'<b>\1</b>', text)
    return text

def text_to_cypher_for_recomm(llm, state:GraphState):
    print(f"Text2Cypher for SEARCH".ljust(100, '-'))
    response = llm.invoke(
        TEXT_TO_CYPHER_FOR_RECOMM_TEMPLATE.format(
            NEO4J_SCHEMA_RECOMM=NEO4J_SCHEMA_RECOMM,
            EXAMPLES_COMBINED=EXAMPLES_COMBINED, 
            query=state['query']
            )
    )
    print(f"# input_tokens count : {response.usage_metadata['input_tokens']}")
    cypher = response.content.replace('```', '').replace('cypher', '').strip()
    print(f"cypher : {cypher}")
    state['t2c_for_recomm'] = cypher
    return state

def get_store_candidates(llm, graphdb_driver, store_retriever_rev_emb, state:GraphState):
    placeholder = st.empty()
    placeholder.markdown("> ë¦¬ë·° ê²€ìƒ‰ì¤‘...", unsafe_allow_html=True)
    # Review similarity
    intent_guide = """
    <div style="background-color: #f9f9f9; padding: 20px; border-radius: 10px; box-shadow: 2px 2px 12px rgba(0, 0, 0, 0.1);">
        <h5 style="font-size: 16px; margin-bottom: 10px;">ğŸ” ì§ˆë¬¸ ì˜ë„ íŒŒì•… ë° ì•Œë§ì€ ë¦¬ë·°ë¥¼ ì°¾ëŠ” ì¤‘...</h5>
        <ul style="list-style-type: none; padding-left: 0;">
    """
    review_candidates_lst = []
    # queryì— ëŒ€í•œ ë¦¬ë·° CONFIG.store_retriever_rev_emb_kê°œ í›„ë³´ì— ì¶”ê°€
    rev_sim_result = store_retriever_rev_emb.invoke(state['query'])
    for document in rev_sim_result:
        if document.metadata['pk'] not in [d.metadata['pk'] for d in review_candidates_lst]:  # ì¤‘ë³µë°©ì§€
            review_candidates_lst.append(document)

    # intentë³„ CONFIG.store_retriever_rev_emb_kê°œì”© í›„ë³´ì— ì¶”ê°€
    for intent in state['intent']:
        converted_intent = convert_markdown_to_html(intent)  # ë§ˆí¬ë‹¤ìš´ì„ HTMLë¡œ ë³€í™˜
        intent_guide += f"<li style='margin-bottom: 8px;'>{converted_intent}</li>"
        rev_sim_result = store_retriever_rev_emb.invoke(intent)  # invokeëŠ” ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ë©”ì„œë“œ
        for document in rev_sim_result:
            store_name = document.metadata['storeName']
            review_text = document.page_content  # í˜ì´ì§€ ë‚´ìš©ì— ì ‘ê·¼í•  ë•ŒëŠ” page_content
            print(f"Store Name: {store_name}")
            print(f"Review Text: {review_text}")
            print()
            if document.metadata['pk'] not in [d.metadata['pk'] for d in review_candidates_lst]:  # ì¤‘ë³µë°©ì§€
                review_candidates_lst.append(document)

    state['candidate_str'] = get_candidate_str(review_candidates_lst)

    # Text2Cypher
    placeholder.markdown(
        f"ë¦¬ë·° ê²€ìƒ‰ ê²°ê³¼ {len(review_candidates_lst)}ê°œ, ë°ì´í„° ë² ì´ìŠ¤ ê²€ìƒ‰ì¤‘...",
        unsafe_allow_html=True,
    )
    state = text_to_cypher_for_recomm(llm, state)
    records, summary, keys = graphdb_driver.execute_query(state['t2c_for_recomm'])
    # pk ê¸°ì¤€ ì¤‘ë³µ ì œê±°
    records_drop_dup = []
    for r in records:
        if r['pk'] not in [d['pk'] for d in records_drop_dup]:
            records_drop_dup.append(r)
    embedding_model = get_embedding_model()
    query_embedding = embedding_model.embed_query(state['query'])
    state['candidate_str'] += '\n'
    for r in records_drop_dup:
        r_keys = r.keys()
        one_record_str = ''
        for key in r_keys:
            one_record_str += f"{key} : {str(r[key])[:100]}\n"
            if key == 'pk':
                reviews = retrieve_top_k_reviews(r[key], query_embedding, graphdb_driver, k=2)
                if reviews:
                    reviews_lst = [f"{ri}. {review['text'][:100]}" for ri, review in enumerate(reviews, start=1)]
                    one_record_str += f"ë¦¬ë·° : {', '.join(reviews_lst)}\n"
        if 'ë¦¬ë·°' in one_record_str:
            state["candidate_str"] += one_record_str
    placeholder.markdown(
        f"> ë¦¬ë·° ê²€ìƒ‰ ê²°ê³¼ í›„ë³´ : {len(review_candidates_lst)}ê°œ, ë°ì´í„° ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ í›„ë³´ : { len(records_drop_dup)}ê°œ",
        unsafe_allow_html=True,
    )
    intent_guide += f"""  	</ul>
<h5 style="font-size: 16px;">â³ ì§ˆë¬¸ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” {len(review_candidates_lst) + len(records)}ê°œì˜ í›„ë³´ ì¤‘ì—ì„œ ìµœì ì˜ ì¶”ì²œ ê²°ê³¼ ì„ ë³„ ì¤‘...</h5>

</div>"""
    st.markdown(intent_guide, unsafe_allow_html=True)

    return state


def retrieve_top_k_reviews(store_pk, query_embedding, driver, k=3):
    """
    íŠ¹ì • STORE ë…¸ë“œì— ì—°ê²°ëœ ë¦¬ë·° ì¤‘ ìœ ì‚¬í•œ TOP-K ë¦¬ë·°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    query = """
    MATCH (s:STORE {pk: $store_pk})-[:HAS_REVIEW]->(r:Review)
    WHERE r.textEmbedding IS NOT NULL
    RETURN r.text AS text, gds.similarity.cosine(r.textEmbedding, $query_embedding) AS similarity
    ORDER BY similarity DESC
    LIMIT $k
    """
    with driver.session() as session:
        result = session.run(
            query, store_pk=store_pk, query_embedding=query_embedding, k=k
        )
        return [
            {"text": record["text"], "similarity": record["similarity"]}
            for record in result
        ]
